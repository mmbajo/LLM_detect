{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "TARGET_MODEL = \"mistralai/Mistral-7B-v0.1\"\n",
    "\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "OUTPUT_DIR = Path(\"../output\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "INPUT_DIR = Path(\"../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df.shape: (15867, 2)\n",
      "test_df.shape: (3, 3)\n",
      "external_df.shape: (2421, 4)\n",
      "train_prompts_df.shape: (2, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(INPUT_DIR / \"train_essays_RDizzl3_seven_v1.csv\", sep=',')\n",
    "test_df = pd.read_csv(INPUT_DIR / \"llm-detect-ai-generated-text/test_essays.csv\", sep=',')\n",
    "external_df = pd.read_csv(INPUT_DIR / \"daigt-external-dataset/daigt_external_dataset.csv\", sep=',')\n",
    "train_prompts_df = pd.read_csv(INPUT_DIR / \"llm-detect-ai-generated-text/train_prompts.csv\", sep=',')\n",
    "\n",
    "# show shape\n",
    "print(f'train_df.shape: {train_df.shape}')\n",
    "print(f'test_df.shape: {test_df.shape}')\n",
    "print(f'external_df.shape: {external_df.shape}')\n",
    "print(f'train_prompts_df.shape: {train_prompts_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.rename(columns={'generated': 'label'})\n",
    "test_df = test_df.rename(columns={'generated': 'label'})\n",
    "external_df = external_df.rename(columns={'generated': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    14247\n",
       "1     1620\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cars. Cars have been around since they became ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transportation is a large necessity in most co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"America's love affair with it's vehicles seem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Cars. Cars have been around since they became ...      0\n",
       "1  Transportation is a large necessity in most co...      0\n",
       "2  \"America's love affair with it's vehicles seem...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>2</td>\n",
       "      <td>Aaa bbb ccc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111bbbb</td>\n",
       "      <td>3</td>\n",
       "      <td>Bbb ccc ddd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2222cccc</td>\n",
       "      <td>4</td>\n",
       "      <td>CCC ddd eee.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  prompt_id          text\n",
       "0  0000aaaa          2  Aaa bbb ccc.\n",
       "1  1111bbbb          3  Bbb ccc ddd.\n",
       "2  2222cccc          4  CCC ddd eee."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>instructions</th>\n",
       "      <th>source_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6060D28C05B6</td>\n",
       "      <td>Some schools in United States ofter classes fr...</td>\n",
       "      <td>\\nTask: Write a persuasive essay on whether or...</td>\n",
       "      <td>\\nWhen considering the pros and cons of attend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60623DB5DE7A</td>\n",
       "      <td>Four-day work week, a remarkable idea to conse...</td>\n",
       "      <td>\\nTask: Research the advantages and disadvanta...</td>\n",
       "      <td>\\nOne of the primary arguments for implementin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>607A39D981DE</td>\n",
       "      <td>Students and their families should consider an...</td>\n",
       "      <td>\\nTask: \\n\\n1. Talk to your parents before tak...</td>\n",
       "      <td>\\nBefore making any decisions about getting in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text  \\\n",
       "0  6060D28C05B6  Some schools in United States ofter classes fr...   \n",
       "1  60623DB5DE7A  Four-day work week, a remarkable idea to conse...   \n",
       "2  607A39D981DE  Students and their families should consider an...   \n",
       "\n",
       "                                        instructions  \\\n",
       "0  \\nTask: Write a persuasive essay on whether or...   \n",
       "1  \\nTask: Research the advantages and disadvanta...   \n",
       "2  \\nTask: \\n\\n1. Talk to your parents before tak...   \n",
       "\n",
       "                                         source_text  \n",
       "0  \\nWhen considering the pros and cons of attend...  \n",
       "1  \\nOne of the primary arguments for implementin...  \n",
       "2  \\nBefore making any decisions about getting in...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "external_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataframe has shape: (18288, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cars. Cars have been around since they became ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transportation is a large necessity in most co...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"America's love affair with it's vehicles seem...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How often do you ride in a car? Do you drive a...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cars are a wonderful thing. They are perhaps o...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label   id\n",
       "0  Cars. Cars have been around since they became ...      0  NaN\n",
       "1  Transportation is a large necessity in most co...      0  NaN\n",
       "2  \"America's love affair with it's vehicles seem...      0  NaN\n",
       "3  How often do you ride in a car? Do you drive a...      0  NaN\n",
       "4  Cars are a wonderful thing. They are perhaps o...      0  NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "external_df = external_df[[\"id\", \"source_text\"]]\n",
    "external_df.columns = [\"id\", \"text\"]\n",
    "external_df['text'] = external_df['text'].str.replace('\\n', '')\n",
    "external_df[\"label\"] = 1\n",
    "\n",
    "train_df = pd.concat([train_df, external_df])\n",
    "train_df.reset_index(inplace=True, drop=True)\n",
    "print(f\"Train dataframe has shape: {train_df.shape}\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    14247\n",
       "1     4041\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.value_counts(\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  label\n",
      "0.0   0        2850\n",
      "      1         808\n",
      "1.0   0        2850\n",
      "      1         808\n",
      "2.0   0        2849\n",
      "      1         809\n",
      "3.0   0        2849\n",
      "      1         808\n",
      "4.0   0        2849\n",
      "      1         808\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cars. Cars have been around since they became ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transportation is a large necessity in most co...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"America's love affair with it's vehicles seem...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How often do you ride in a car? Do you drive a...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cars are a wonderful thing. They are perhaps o...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label   id  fold\n",
       "0  Cars. Cars have been around since they became ...      0  NaN   1.0\n",
       "1  Transportation is a large necessity in most co...      0  NaN   3.0\n",
       "2  \"America's love affair with it's vehicles seem...      0  NaN   0.0\n",
       "3  How often do you ride in a car? Do you drive a...      0  NaN   2.0\n",
       "4  Cars are a wonderful thing. They are perhaps o...      0  NaN   3.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "X = train_df.loc[:, train_df.columns != \"label\"]\n",
    "y = train_df.loc[:, train_df.columns == \"label\"]\n",
    "\n",
    "for i, (train_index, valid_index) in enumerate(skf.split(X, y)):\n",
    "    train_df.loc[valid_index, \"fold\"] = i\n",
    "    \n",
    "print(train_df.groupby(\"fold\")[\"label\"].value_counts())\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = train_df[train_df[\"fold\"] == 0]\n",
    "train_df = train_df[train_df[\"fold\"] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType # type: ignore\n",
    "from transformers import BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=64,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    inference_mode=False,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"v_proj\"\n",
    "    ],\n",
    ")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, LlamaForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(TARGET_MODEL, use_fast=False)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type mistral to instantiate a model of type llama. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "474d5adce93a46d395fc18807ed98cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at mistralai/Mistral-7B-v0.1 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "base_model = LlamaForSequenceClassification.from_pretrained(\n",
    "    TARGET_MODEL,\n",
    "    num_labels=2,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map={\"\":1}\n",
    ")\n",
    "base_model.config.pretraining_tp = 1 # 1 is 7b\n",
    "base_model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_peft_model(base_model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 27,271,168 || all params: 7,137,939,456 || trainable%: 0.3820593907822577\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    11397\n",
      "1     3233\n",
      "Name: count, dtype: int64 label\n",
      "0    2850\n",
      "1     808\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# debug\n",
    "if DEBUG:\n",
    "    train_df = train_df.sample(300)\n",
    "    valid_df = valid_df.sample(50)\n",
    "#train_df = train_df.sample(100)\n",
    "#valid_df = valid_df.sample(30)\n",
    "print(train_df.label.value_counts(), valid_df.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "# from pandas\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "valid_ds = Dataset.from_pandas(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples, max_length=512):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, max_length=max_length, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06a4605a670f4d77b556860c77718b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14630 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9093d9bb334e42b1bea4104d03e78c43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3658 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_tokenized_ds = train_ds.map(preprocess_function, batched=True)\n",
    "valid_tokenized_ds = valid_ds.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=\"longest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    accuracy_val = accuracy_score(labels, predictions)\n",
    "    roc_auc_val = roc_auc_score(labels, predictions)\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy_val,\n",
    "        \"roc_auc\": roc_auc_val,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You can't train a model that has been loaded in 8-bit precision on a different device than the one you're training on. Make sure you loaded the model on the correct device using for example `device_map={'':torch.cuda.current_device()}you're training on. Make sure you loaded the model on the correct device using for example `device_map={'':torch.cuda.current_device() or device_map={'':torch.xpu.current_device()}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/LLM_detect/notebooks/mistral.ipynb Cell 24\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f6d62616a6f2f4c4c4d5f646574656374222c226c6f63616c446f636b6572223a66616c73652c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6d62616a6f2f4c4c4d5f6465746563742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d@ssh-remote%2B7b22686f73744e616d65223a224447585f325f31227d/workspaces/LLM_detect/notebooks/mistral.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m training_args \u001b[39m=\u001b[39m TrainingArguments(\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f6d62616a6f2f4c4c4d5f646574656374222c226c6f63616c446f636b6572223a66616c73652c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6d62616a6f2f4c4c4d5f6465746563742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d@ssh-remote%2B7b22686f73744e616d65223a224447585f325f31227d/workspaces/LLM_detect/notebooks/mistral.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     output_dir\u001b[39m=\u001b[39mOUTPUT_DIR,\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f6d62616a6f2f4c4c4d5f646574656374222c226c6f63616c446f636b6572223a66616c73652c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6d62616a6f2f4c4c4d5f6465746563742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d@ssh-remote%2B7b22686f73744e616d65223a224447585f325f31227d/workspaces/LLM_detect/notebooks/mistral.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     learning_rate\u001b[39m=\u001b[39m\u001b[39m5e-5\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f6d62616a6f2f4c4c4d5f646574656374222c226c6f63616c446f636b6572223a66616c73652c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6d62616a6f2f4c4c4d5f6465746563742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d@ssh-remote%2B7b22686f73744e616d65223a224447585f325f31227d/workspaces/LLM_detect/notebooks/mistral.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m     report_to\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m \u001b[39m# if DEBUG else 'wandb',\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f6d62616a6f2f4c4c4d5f646574656374222c226c6f63616c446f636b6572223a66616c73652c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6d62616a6f2f4c4c4d5f6465746563742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d@ssh-remote%2B7b22686f73744e616d65223a224447585f325f31227d/workspaces/LLM_detect/notebooks/mistral.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f6d62616a6f2f4c4c4d5f646574656374222c226c6f63616c446f636b6572223a66616c73652c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6d62616a6f2f4c4c4d5f6465746563742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d@ssh-remote%2B7b22686f73744e616d65223a224447585f325f31227d/workspaces/LLM_detect/notebooks/mistral.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f6d62616a6f2f4c4c4d5f646574656374222c226c6f63616c446f636b6572223a66616c73652c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6d62616a6f2f4c4c4d5f6465746563742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d@ssh-remote%2B7b22686f73744e616d65223a224447585f325f31227d/workspaces/LLM_detect/notebooks/mistral.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f6d62616a6f2f4c4c4d5f646574656374222c226c6f63616c446f636b6572223a66616c73652c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6d62616a6f2f4c4c4d5f6465746563742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d@ssh-remote%2B7b22686f73744e616d65223a224447585f325f31227d/workspaces/LLM_detect/notebooks/mistral.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f6d62616a6f2f4c4c4d5f646574656374222c226c6f63616c446f636b6572223a66616c73652c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6d62616a6f2f4c4c4d5f6465746563742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d@ssh-remote%2B7b22686f73744e616d65223a224447585f325f31227d/workspaces/LLM_detect/notebooks/mistral.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m     compute_metrics\u001b[39m=\u001b[39mcompute_metrics,\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f6d62616a6f2f4c4c4d5f646574656374222c226c6f63616c446f636b6572223a66616c73652c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6d62616a6f2f4c4c4d5f6465746563742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d@ssh-remote%2B7b22686f73744e616d65223a224447585f325f31227d/workspaces/LLM_detect/notebooks/mistral.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f6d62616a6f2f4c4c4d5f646574656374222c226c6f63616c446f636b6572223a66616c73652c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6d62616a6f2f4c4c4d5f6465746563742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d@ssh-remote%2B7b22686f73744e616d65223a224447585f325f31227d/workspaces/LLM_detect/notebooks/mistral.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m/transformers/src/transformers/trainer.py:1556\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1554\u001b[0m         hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1555\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1556\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1557\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1558\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1559\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1560\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1561\u001b[0m     )\n",
      "File \u001b[0;32m/transformers/src/transformers/trainer.py:1690\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1688\u001b[0m         model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39mprepare(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel)\n\u001b[1;32m   1689\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1690\u001b[0m         model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maccelerator\u001b[39m.\u001b[39;49mprepare(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer)\n\u001b[1;32m   1691\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1692\u001b[0m     \u001b[39m# to handle cases wherein we pass \"DummyScheduler\" such as when it is specified in DeepSpeed config.\u001b[39;00m\n\u001b[1;32m   1693\u001b[0m     model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlr_scheduler \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39mprepare(\n\u001b[1;32m   1694\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlr_scheduler\n\u001b[1;32m   1695\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py:1288\u001b[0m, in \u001b[0;36mAccelerator.prepare\u001b[0;34m(self, device_placement, *args)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_megatron_lm(\u001b[39m*\u001b[39margs)\n\u001b[1;32m   1287\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39;49m(\n\u001b[1;32m   1289\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_one(obj, first_pass\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, device_placement\u001b[39m=\u001b[39;49md) \u001b[39mfor\u001b[39;49;00m obj, d \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(args, device_placement)\n\u001b[1;32m   1290\u001b[0m     )\n\u001b[1;32m   1291\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_one(obj, device_placement\u001b[39m=\u001b[39md) \u001b[39mfor\u001b[39;00m obj, d \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(result, device_placement))\n\u001b[1;32m   1293\u001b[0m \u001b[39mif\u001b[39;00m tpu_should_fix_optimizer \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmixed_precision \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfp8\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1294\u001b[0m     \u001b[39m# 2. grabbing new model parameters\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py:1289\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_megatron_lm(\u001b[39m*\u001b[39margs)\n\u001b[1;32m   1287\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\n\u001b[0;32m-> 1289\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_one(obj, first_pass\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, device_placement\u001b[39m=\u001b[39;49md) \u001b[39mfor\u001b[39;00m obj, d \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(args, device_placement)\n\u001b[1;32m   1290\u001b[0m     )\n\u001b[1;32m   1291\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_one(obj, device_placement\u001b[39m=\u001b[39md) \u001b[39mfor\u001b[39;00m obj, d \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(result, device_placement))\n\u001b[1;32m   1293\u001b[0m \u001b[39mif\u001b[39;00m tpu_should_fix_optimizer \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmixed_precision \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfp8\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1294\u001b[0m     \u001b[39m# 2. grabbing new model parameters\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py:1094\u001b[0m, in \u001b[0;36mAccelerator._prepare_one\u001b[0;34m(self, obj, first_pass, device_placement)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_data_loader(obj, device_placement\u001b[39m=\u001b[39mdevice_placement)\n\u001b[1;32m   1093\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule):\n\u001b[0;32m-> 1094\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprepare_model(obj, device_placement\u001b[39m=\u001b[39;49mdevice_placement)\n\u001b[1;32m   1095\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mOptimizer):\n\u001b[1;32m   1096\u001b[0m     optimizer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_optimizer(obj, device_placement\u001b[39m=\u001b[39mdevice_placement)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py:1376\u001b[0m, in \u001b[0;36mAccelerator.prepare_model\u001b[0;34m(self, model, device_placement, evaluation_mode)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mdevice(current_device_index) \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice:\n\u001b[1;32m   1374\u001b[0m     \u001b[39m# if on the first device (GPU 0) we don't care\u001b[39;00m\n\u001b[1;32m   1375\u001b[0m     \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\u001b[39m.\u001b[39mindex \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mor\u001b[39;00m (current_device_index \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[0;32m-> 1376\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1377\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mYou can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt train a model that has been loaded in 8-bit precision on a different device than the one \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1378\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myou\u001b[39m\u001b[39m'\u001b[39m\u001b[39mre training on. Make sure you loaded the model on the correct device using for example `device_map=\u001b[39m\u001b[39m{\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m:torch.cuda.current_device()}\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1379\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myou\u001b[39m\u001b[39m'\u001b[39m\u001b[39mre training on. Make sure you loaded the model on the correct device using for example `device_map=\u001b[39m\u001b[39m{\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m:torch.cuda.current_device() or device_map=\u001b[39m\u001b[39m{\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m:torch.xpu.current_device()}\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1380\u001b[0m         )\n\u001b[1;32m   1382\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m model_devices \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mdisk\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m model_devices:\n\u001b[1;32m   1383\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1384\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt train a model that has been loaded in 8-bit precision with CPU or disk offload.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1385\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: You can't train a model that has been loaded in 8-bit precision on a different device than the one you're training on. Make sure you loaded the model on the correct device using for example `device_map={'':torch.cuda.current_device()}you're training on. Make sure you loaded the model on the correct device using for example `device_map={'':torch.cuda.current_device() or device_map={'':torch.xpu.current_device()}"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "steps = 5 if DEBUG else 20\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=16,\n",
    "    max_grad_norm=0.3,\n",
    "    optim='paged_adamw_32bit',\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    "    warmup_steps=steps,\n",
    "    eval_steps=steps,\n",
    "    logging_steps=steps,\n",
    "    report_to='none' # if DEBUG else 'wandb',\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized_ds,\n",
    "    eval_dataset=valid_tokenized_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import rmtree\n",
    "\n",
    "trainer.save_model(output_dir=str(OUTPUT_DIR))\n",
    "\n",
    "for path in Path(training_args.output_dir).glob(\"checkpoint-*\"):\n",
    "    if path.is_dir():\n",
    "        rmtree(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForSequenceClassification(\n",
      "  (base_model): LoraModel(\n",
      "    (model): LlamaForSequenceClassification(\n",
      "      (model): LlamaModel(\n",
      "        (embed_tokens): Embedding(32000, 4096)\n",
      "        (layers): ModuleList(\n",
      "          (0-31): 32 x LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): Linear4bit(\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "              )\n",
      "              (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "              (v_proj): Linear4bit(\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=64, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "              )\n",
      "              (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "              (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "              (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm()\n",
      "            (post_attention_layernorm): LlamaRMSNorm()\n",
      "          )\n",
      "        )\n",
      "        (norm): LlamaRMSNorm()\n",
      "      )\n",
      "      (score): ModulesToSaveWrapper(\n",
      "        (original_module): Linear(in_features=4096, out_features=2, bias=False)\n",
      "        (modules_to_save): ModuleDict(\n",
      "          (default): Linear(in_features=4096, out_features=2, bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "del trainer, model, base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda cache clear\n",
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model / tokenizer with 4bit bnb\n",
    "\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType # type: ignore\n",
    "from transformers import BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, LlamaForSequenceClassification\n",
    "\n",
    "base_model = LlamaForSequenceClassification.from_pretrained(\n",
    "    TARGET_MODEL,\n",
    "    num_labels=2,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map={\"\":0}\n",
    ")\n",
    "base_model.config.pretraining_tp = 1 # 1 is 7b\n",
    "base_model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PeftModel.from_pretrained(base_model, str(OUTPUT_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_output = trainer.predict(valid_tokenized_ds)\n",
    "logits = pred_output.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = pred_output.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.special import expit as sigmoid\n",
    "import numpy as np\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))  \n",
    "probs = sigmoid(logits[:, 1])\n",
    "probs.shape, probs[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['id'] = valid_df['id']\n",
    "sub['generated'] = probs\n",
    "# sub.to_csv('submission.csv', index=False)\n",
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
